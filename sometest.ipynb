{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/william/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import helpers.NNUtils as nnu\n",
    "\n",
    "train_dataset, test_dataset, val_dataset = nnu.loadMNISTDatasets()\n",
    "train_loader, test_loader, val_loader = nnu.getMNISTLoaders(\n",
    "    [train_dataset, test_dataset, val_dataset],\n",
    "    batch_size=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import MLPOne\n",
    "\n",
    "model = nnu.loadModel(MLPOne(), \"simpleMLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.analysis.ConfusionMatrix import ConfusionMatrix\n",
    "\n",
    "cm = ConfusionMatrix(model, train_dataset.dataset)\n",
    "#cm.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.analysis.TB import TB\n",
    "\n",
    "#t = TB()\n",
    "#t.plotModel(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import OrderedDict\n",
    "# from helpers.run import RunBuilder, RunManager\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# params = OrderedDict(\n",
    "#     lr = [.01, .001],\n",
    "#     batch_size = [1000, 10000]\n",
    "# )\n",
    "\n",
    "# m = RunManager()\n",
    "# for run in RunBuilder.get_runs(params):\n",
    "#     model = MLPOne()\n",
    "#     loader = DataLoader(train_dataset, batch_size=run.batch_size)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=run.lr)\n",
    "\n",
    "#     m.begin_run(run, model, loader)\n",
    "#     for epoch in range(5):\n",
    "#         m.begin_epoch()\n",
    "#         for batch in train_loader:\n",
    "#             images, labels = batch # Get Batch\n",
    "#             preds = model(images) # Pass Batch\n",
    "#             loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "#             optimizer.zero_grad() # Zero Gradients\n",
    "#             loss.backward() # Calculate Gradients\n",
    "#             optimizer.step() # Update Weights\n",
    "                \n",
    "#             m.track_loss(loss, batch)\n",
    "#             m.track_num_correct(preds, labels)\n",
    "\n",
    "#         m.end_epoch()\n",
    "#     m.end_run()\n",
    "# m.save('results')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   run  epoch      loss   valLoss  accuracy  accuracy_val    lr  batch_size  \\\n0    1      1  0.087929  0.109117  0.974771      0.967333  0.01        1000   \n1    1      2  0.077907  0.102998  0.977792      0.968333  0.01        1000   \n2    1      3  0.073498  0.099793  0.979208      0.970000  0.01        1000   \n3    1      4  0.070930  0.097758  0.979812      0.970917  0.01        1000   \n4    1      5  0.069169  0.096289  0.980375      0.971250  0.01        1000   \n5    2      1  0.673843  0.144257  0.888104      0.956500  0.01        1000   \n6    2      2  0.103286  0.112128  0.969292      0.966417  0.01        1000   \n7    2      3  0.071604  0.103848  0.978292      0.968333  0.01        1000   \n8    2      4  0.054892  0.101239  0.983583      0.969667  0.01        1000   \n9    2      5  0.042138  0.098012  0.988021      0.970417  0.01        1000   \n\n  optim  \n0   sgd  \n1   sgd  \n2   sgd  \n3   sgd  \n4   sgd  \n5  adam  \n6  adam  \n7  adam  \n8  adam  \n9  adam  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run</th>\n      <th>epoch</th>\n      <th>loss</th>\n      <th>valLoss</th>\n      <th>accuracy</th>\n      <th>accuracy_val</th>\n      <th>lr</th>\n      <th>batch_size</th>\n      <th>optim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.087929</td>\n      <td>0.109117</td>\n      <td>0.974771</td>\n      <td>0.967333</td>\n      <td>0.01</td>\n      <td>1000</td>\n      <td>sgd</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.077907</td>\n      <td>0.102998</td>\n      <td>0.977792</td>\n      <td>0.968333</td>\n      <td>0.01</td>\n      <td>1000</td>\n      <td>sgd</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.073498</td>\n      <td>0.099793</td>\n      <td>0.979208</td>\n      <td>0.970000</td>\n      <td>0.01</td>\n      <td>1000</td>\n      <td>sgd</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.070930</td>\n      <td>0.097758</td>\n      <td>0.979812</td>\n      <td>0.970917</td>\n      <td>0.01</td>\n      <td>1000</td>\n      <td>sgd</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>0.069169</td>\n      <td>0.096289</td>\n      <td>0.980375</td>\n      <td>0.971250</td>\n      <td>0.01</td>\n      <td>1000</td>\n      <td>sgd</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>1</td>\n      <td>0.673843</td>\n      <td>0.144257</td>\n      <td>0.888104</td>\n      <td>0.956500</td>\n      <td>0.01</td>\n      <td>1000</td>\n      <td>adam</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>2</td>\n      <td>0.103286</td>\n      <td>0.112128</td>\n      <td>0.969292</td>\n      <td>0.966417</td>\n      <td>0.01</td>\n      <td>1000</td>\n      <td>adam</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0.071604</td>\n      <td>0.103848</td>\n      <td>0.978292</td>\n      <td>0.968333</td>\n      <td>0.01</td>\n      <td>1000</td>\n      <td>adam</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>4</td>\n      <td>0.054892</td>\n      <td>0.101239</td>\n      <td>0.983583</td>\n      <td>0.969667</td>\n      <td>0.01</td>\n      <td>1000</td>\n      <td>adam</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2</td>\n      <td>5</td>\n      <td>0.042138</td>\n      <td>0.098012</td>\n      <td>0.988021</td>\n      <td>0.970417</td>\n      <td>0.01</td>\n      <td>1000</td>\n      <td>adam</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from helpers.run import RunManager\n",
    "import torch.nn.functional as F\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [.01],\n",
    "    batch_size = [1000],\n",
    "    optim = [\"sgd\", \"adam\"]\n",
    ")\n",
    "\n",
    "loss_fn = F.cross_entropy\n",
    "\n",
    "RunManager(name=\"testOptim\").fit(model, 5, params, loss_fn, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}