{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stretch-instrumentation",
   "metadata": {},
   "source": [
    "# Evaluate to performance of model(s) according to hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "specialized-annex",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sklearn.metrics as skm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from helpers.mnist_loader import loadMNISTDatasets, getMNISTLoaders\n",
    "import helpers.evaluation as evaluation\n",
    "\n",
    "import models.MLP as MLPs\n",
    "import models.CNN as CNNs\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 5)\n",
    "\n",
    "train_dataset, val_dataset, holdback_dataset = loadMNISTDatasets()\n",
    "_,_, holdback_loader = getMNISTLoaders([train_dataset, val_dataset, holdback_dataset],batch_size=1000)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-bernard",
   "metadata": {},
   "source": [
    "## Load the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "therapeutic-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = \"two_test_60epochs\"\n",
    "\n",
    "if not os.path.exists(f'results/{results_file}.csv'):\n",
    "    print('ERROR missing training file! Try retraining to produce the needed file!')\n",
    "else:\n",
    "    model_hp_log = pd.read_csv(f'results/{results_file}.csv', index_col=0, usecols=[0,2,3,4,5,6,7,8])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "controlling-demand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.9110</td>\n",
       "      <td>0.9584</td>\n",
       "      <td>0.2</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1876</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>0.9412</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.2</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0.9551</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.2</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1013</td>\n",
       "      <td>0.9631</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.2</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.9709</td>\n",
       "      <td>0.2</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    loss  val_loss  accuracy  val_accuracy  learning_rate  batch_size\n",
       "0      1  0.2836    0.1333    0.9110        0.9584            0.2          64\n",
       "1      2  0.1876    0.1151    0.9412        0.9643            0.2          64\n",
       "2      3  0.1437    0.1047    0.9551        0.9681            0.2          64\n",
       "3      4  0.1178    0.1013    0.9631        0.9697            0.2          64\n",
       "4      5  0.1000    0.0986    0.9687        0.9709            0.2          64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hp_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "controversial-treasurer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0975</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.20</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>60</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>0.9777</td>\n",
       "      <td>0.20</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>60</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.9547</td>\n",
       "      <td>0.02</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>60</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>0.3242</td>\n",
       "      <td>0.8907</td>\n",
       "      <td>0.8772</td>\n",
       "      <td>0.02</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch    loss  val_loss  accuracy  val_accuracy  learning_rate  \\\n",
       "59      60  0.0091    0.0975    0.9972        0.9814           0.20   \n",
       "119     60  0.0205    0.0920    0.9943        0.9777           0.20   \n",
       "239     60  0.1383    0.1570    0.9622        0.9547           0.02   \n",
       "179     60  0.2698    0.3242    0.8907        0.8772           0.02   \n",
       "\n",
       "     batch_size  \n",
       "59           64  \n",
       "119         256  \n",
       "239         256  \n",
       "179          64  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epochs = 60\n",
    "\n",
    "model_hp_log[model_hp_log.epoch == nb_epochs].sort_values(by=['val_accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-fitting",
   "metadata": {},
   "source": [
    "### Choosing best models\n",
    "\n",
    "with the above table, we can choose the hyperparameters that yield the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "commercial-hindu",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3718</td>\n",
       "      <td>0.1841</td>\n",
       "      <td>0.8903</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>0.07</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>0.1564</td>\n",
       "      <td>0.9247</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.07</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>3</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1391</td>\n",
       "      <td>0.9404</td>\n",
       "      <td>0.9584</td>\n",
       "      <td>0.07</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1704</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9617</td>\n",
       "      <td>0.07</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>5</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.9567</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>0.07</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>76</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>0.9799</td>\n",
       "      <td>0.07</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>77</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.07</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>78</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.07</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>79</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.07</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>80</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.07</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch    loss  val_loss  accuracy  val_accuracy  learning_rate  \\\n",
       "320      1  0.3718    0.1841    0.8903        0.9437           0.07   \n",
       "321      2  0.2560    0.1564    0.9247        0.9536           0.07   \n",
       "322      3  0.2028    0.1391    0.9404        0.9584           0.07   \n",
       "323      4  0.1704    0.1276    0.9500        0.9617           0.07   \n",
       "324      5  0.1477    0.1192    0.9567        0.9642           0.07   \n",
       "..     ...     ...       ...       ...           ...            ...   \n",
       "395     76  0.0141    0.0733    0.9965        0.9799           0.07   \n",
       "396     77  0.0140    0.0734    0.9965        0.9800           0.07   \n",
       "397     78  0.0138    0.0734    0.9966        0.9800           0.07   \n",
       "398     79  0.0136    0.0734    0.9966        0.9800           0.07   \n",
       "399     80  0.0135    0.0734    0.9967        0.9800           0.07   \n",
       "\n",
       "     batch_size  \n",
       "320          64  \n",
       "321          64  \n",
       "322          64  \n",
       "323          64  \n",
       "324          64  \n",
       "..          ...  \n",
       "395          64  \n",
       "396          64  \n",
       "397          64  \n",
       "398          64  \n",
       "399          64  \n",
       "\n",
       "[80 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = .07\n",
    "best_bs = 64\n",
    "\n",
    "best_one = model_hp_log[\n",
    "            (model_hp_log.learning_rate == best_lr) & \n",
    "            (model_hp_log.batch_size == best_bs)\n",
    "           ]\n",
    "best_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "residential-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name= f'results/{results_file}_best.csv'\n",
    "\n",
    "if os.path.exists(best_name):\n",
    "    print('ERROR Best model file already exists!')\n",
    "else:\n",
    "    best_one.to_csv(best_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-scanning",
   "metadata": {},
   "source": [
    "### Checking accuracy on the holdback set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "contrary-basis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_MLPTwo_learning_rate_0.02_batch_size_64_optimizer_sgd\n",
      "model_MLPTwo_learning_rate_0.07_batch_size_256_optimizer_sgd\n",
      "model_MLPTwo_learning_rate_0.02_batch_size_256_optimizer_sgd\n",
      "model_MLPTwo_learning_rate_0.07_batch_size_64_optimizer_sgd\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "model_type = \"MLPTwo\"\n",
    "models = []\n",
    "for f in glob.glob(f\"./models/saved/model_{model_type}_*\"):\n",
    "    models.append(f.split(\"/\")[3])\n",
    "    print(models[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "early-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model: model_MLPTwo_learning_rate_0.02_batch_size_64_optimizer_sgd\n",
      "\n",
      "HoldBackSet: Avg. loss: 0.0003, Accuracy: 0.887 (88.7%)\n",
      "\n",
      "Current model: model_MLPTwo_learning_rate_0.07_batch_size_256_optimizer_sgd\n",
      "\n",
      "HoldBackSet: Avg. loss: 0.0003, Accuracy: 0.8682 (86.8%)\n",
      "\n",
      "Current model: model_MLPTwo_learning_rate_0.02_batch_size_256_optimizer_sgd\n",
      "\n",
      "HoldBackSet: Avg. loss: 0.0001, Accuracy: 0.977 (97.7%)\n",
      "\n",
      "Current model: model_MLPTwo_learning_rate_0.07_batch_size_64_optimizer_sgd\n",
      "\n",
      "HoldBackSet: Avg. loss: 0.0001, Accuracy: 0.9813 (98.1%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    print(f\"Current model: {m}\")\n",
    "    model = MLPs.MLPTwo()#.to(device)\n",
    "    evaluation.loadModel(model, m);\n",
    "    evaluation.validate(model, F.cross_entropy, holdback_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acoustic-accordance",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/saved/model_MLPTwo_learning_rate_0.07_batch_size_64_optimizer_sgd' -> './models/saved/MLPTwo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-09d369152aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnew_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MLPTwo\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'./models/saved/{new_name}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/saved/model_MLPTwo_learning_rate_0.07_batch_size_64_optimizer_sgd' -> './models/saved/MLPTwo'"
     ]
    }
   ],
   "source": [
    "src=f'./models/saved/{models[3]}'\n",
    "new_name = \"MLPTwo\"\n",
    "dst=f'./models/saved/{new_name}'\n",
    "#os.rename(src,dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
